{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/willstith/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import pickle\n",
    "import string\n",
    "import random\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from itertools import combinations\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#import gensim\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "\n",
    "# sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216930, 7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jdf = pd.read_json('data/jeopardy.json')\n",
    "jdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1179.,   52.,  836.,  346., 1009.,  502.,  422.,  859.,  112.,\n",
       "         780.,  446., 2500., 2734.,  668.,  533.,  850.,  122., 1588.,\n",
       "         539.,  792., 1037.,  181.,  955.,  240., 1319., 1209., 2842.,\n",
       "        5690., 6162., 6156., 6114., 6126., 6159., 6139., 5984., 6308.,\n",
       "        6138., 4761., 1023., 4602., 5990., 4548., 3443., 6278., 6313.,\n",
       "        6362., 6279., 6346., 6176., 6366., 6308., 6346., 6358., 6338.,\n",
       "        6314., 6256., 6261., 6188., 6256., 6190.]),\n",
       " array([1.00000000e+00, 1.05983333e+02, 2.10966667e+02, 3.15950000e+02,\n",
       "        4.20933333e+02, 5.25916667e+02, 6.30900000e+02, 7.35883333e+02,\n",
       "        8.40866667e+02, 9.45850000e+02, 1.05083333e+03, 1.15581667e+03,\n",
       "        1.26080000e+03, 1.36578333e+03, 1.47076667e+03, 1.57575000e+03,\n",
       "        1.68073333e+03, 1.78571667e+03, 1.89070000e+03, 1.99568333e+03,\n",
       "        2.10066667e+03, 2.20565000e+03, 2.31063333e+03, 2.41561667e+03,\n",
       "        2.52060000e+03, 2.62558333e+03, 2.73056667e+03, 2.83555000e+03,\n",
       "        2.94053333e+03, 3.04551667e+03, 3.15050000e+03, 3.25548333e+03,\n",
       "        3.36046667e+03, 3.46545000e+03, 3.57043333e+03, 3.67541667e+03,\n",
       "        3.78040000e+03, 3.88538333e+03, 3.99036667e+03, 4.09535000e+03,\n",
       "        4.20033333e+03, 4.30531667e+03, 4.41030000e+03, 4.51528333e+03,\n",
       "        4.62026667e+03, 4.72525000e+03, 4.83023333e+03, 4.93521667e+03,\n",
       "        5.04020000e+03, 5.14518333e+03, 5.25016667e+03, 5.35515000e+03,\n",
       "        5.46013333e+03, 5.56511667e+03, 5.67010000e+03, 5.77508333e+03,\n",
       "        5.88006667e+03, 5.98505000e+03, 6.09003333e+03, 6.19501667e+03,\n",
       "        6.30000000e+03]),\n",
       " <a list of 60 Patch objects>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(jdf['show_number'], bins=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both because the dataset is very large, and because older clues might be outdated or reflect a different style, I decided to get rid of all clues older than a certain date. I decided a good cutoff for the \"modern era\" would be the beginning of Season 20, when the show did away with its 5-game limit for returning champions. This reduce my dataset from 216,930 clues to 111,162 clues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "jdf = jdf[jdf['show_number'] >= 4380] #first show in the dataset following the beginning of Season 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm also getting rid of all clues containing a link to a picture or video. Many of the clues consist of only the link and lack specific interpretive value. Many others contain dead links, which I would not like to be included in a future training app. This leaves me with 101,742 clues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all non-text clues (audio/picture/video)\n",
    "jdf = jdf[~jdf['question'].str.contains('href')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "jdf['qanda'] = jdf['question'] + ' ' + jdf['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "jdf['qandacat'] = jdf['qanda'] + ' ' + jdf['category']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because each individual question and answer is so short, I might be able to obtain better topics by grouping whole categories together as a single document. Categories normally consist of 5 questions each, but there is more variance in jdf because I've dropped certain Qs and also some Qs are left buried when time runs out in a Jeopardy! match. The ['qanda5'] or ['qanda5cat'] column can serve as the corpus in that case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jdf['qanda5'] = jdf.groupby(['show_number', 'round', 'category'])['qanda'].transform(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jdf['qanda5cat'] = jdf['qanda5'] + ' ' + jdf['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking a smaller sample to work with\n",
    "#jdf = jdf.head(100000)\n",
    "#save questions to use later in question suggester\n",
    "jdf_qanda = jdf[['question', 'answer', 'category']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "jdf_qanda['idx'] = jdf.index.copy()\n",
    "jdf_qanda['question'] = (jdf_qanda['idx'].apply(str) + ' ' + jdf_qanda['category'].apply(str) + ': ' + jdf_qanda['question'].apply(str))\n",
    "jdf_qanda['answer'] = (jdf_qanda['idx'].apply(str) + ' ' + jdf_qanda['answer'].apply(str))\n",
    "jdf_qanda['category'] = (jdf_qanda['idx'].apply(str) + ' ' + jdf_qanda['category'].apply(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(jdf['qandacat'])\n",
    "#delete old df in order to save space\n",
    "del jdf\n",
    "#strip punctuation\n",
    "corpus = [qanda.translate(str.maketrans('', '', string.punctuation)).lower() for qanda in corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stop Words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['thats','also','could','would','im','like','names','name','named','br'])\n",
    "#strip stop_word punctuation so it matches corpus\n",
    "stop_words = [word.translate(str.maketrans('', '', string.punctuation)) for word in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF-IDF with NMF (best combination)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only unigrams but the token pattern also allows for important specifically defined bigrams to be included\n",
    "tfidf2 = TfidfVectorizer(ngram_range=(1,1),\n",
    "                         stop_words=stop_words, token_pattern=\"\\\\b[a-z]+_?[a-z]+\\\\b\")\n",
    "tfidf2.fit(corpus)\n",
    "corpus_tf2 = tfidf2.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/metis/lib/python3.8/site-packages/sklearn/decomposition/_nmf.py:1076: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "nmf2 = NMF(n_components=25, random_state=23)\n",
    "corpus_tf2_nmf = nmf2.fit_transform(corpus_tf2)\n",
    "corpus_tf2_nmf.shape\n",
    "#save this doc-topic matrix as a dataframe to use later\n",
    "corpus_tf2_nmf_df = pd.DataFrame(corpus_tf2_nmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tf2_nmf_df = pd.DataFrame(corpus_tf2_nmf)\n",
    "corpus_tf2_nmf_df['question'] = jdf_qanda['question']\n",
    "corpus_tf2_nmf_df['answer'] = jdf_qanda['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    for ix, topic in enumerate(nmf2.components_):\n",
    "        if not topic_names or not topic_names[ix]:\n",
    "            print(\"\\nTopic \", ix)\n",
    "        else:\n",
    "            print(\"\\nTopic: '\",topic_names[ix],\"'\")\n",
    "        print(\", \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "day, national, park, years, year, may, holiday, days, april, holidays, month, week, every, observances, june, celebrated, parks, st, died, november\n",
      "\n",
      "Topic  1\n",
      "state, official, states, capital, capitals, university, union, texas, california, park, secretary, college, virginia, florida, nicknames, alaska, washington, georgia, bird, hawaii\n",
      "\n",
      "Topic  2\n",
      "one, number, another, letter, famous, largest, good, says, worlds, change, borders, might, need, million, animals, theres, may, many, two, big\n",
      "\n",
      "Topic  3\n",
      "first, became, lady, woman, ladies, alphabetically, year, firsts, sports, published, win, american, women, female, history, space, opened, major, elected, years\n",
      "\n",
      "Topic  4\n",
      "word, comes, meaning, latin, origins, greek, means, french, phrase, english, old, letter, term, adjective, spanish, mean, may, get, derived, dictionary\n",
      "\n",
      "Topic  5\n",
      "new, york, times, jersey, mexico, orleans, zealand, hampshire, england, governor, states, testament, years, news, college, year, yankees, street, cities, old\n",
      "\n",
      "Topic  6\n",
      "city, capital, cities, home, capitals, largest, founded, san, port, river, center, museum, populous, chicago, european, st, kansas, mayor, francisco, london\n",
      "\n",
      "Topic  7\n",
      "war, civil, battle, years, ii, general, revolutionary, ended, peace, wars, spanishamerican, military, treaty, vietnam, french, army, british, cold, korean, history\n",
      "\n",
      "Topic  8\n",
      "us, states, cities, president, presidents, government, department, gave, senate, army, constitution, cabinet, number, history, military, general, flag, senator, million, mexico\n",
      "\n",
      "Topic  9\n",
      "country, countries, african, south, africa, borders, european, china, russia, france, india, germany, spain, canada, italy, central, border, asian, sweden, republic\n",
      "\n",
      "Topic  10\n",
      "words, phrases, term, means, foreign, meaning, something, adjective, long, latin, mean, german, small, person, someone, palindromic, odd, compound, often, part\n",
      "\n",
      "Topic  11\n",
      "time, rhyme, colorful, zone, beastly, period, magazine, machine, nursery, game, tea, long, year, celebrity, crime, short, years, prime, old, presidential\n",
      "\n",
      "Topic  12\n",
      "king, great, queen, british, henry, james, history, kings, ii, iii, louis, became, born, england, royal, died, english, son, stephen, charles\n",
      "\n",
      "Topic  13\n",
      "clues, crossword, literary, french, biblical, opera, history, precedes, partnerbr, itbr, movie, multiply, citybr, value, art, er, aencient, puzzle, precederbr, songbr\n",
      "\n",
      "Topic  14\n",
      "island, american, south, sea, river, lake, water, north, islands, largest, great, states, miles, bodies, geography, america, countries, rivers, west, africa\n",
      "\n",
      "Topic  15\n",
      "tv, show, series, shows, played, game, family, sitcom, star, classic, drama, characters, episode, reality, character, host, jack, dr, night, spinoffs\n",
      "\n",
      "Topic  16\n",
      "world, capital, capitals, history, around, ii, series, leaders, leader, nation, countries, countrys, sports, largest, almanac, facts, nations, prime, minister, became\n",
      "\n",
      "Topic  17\n",
      "john, president, presidential, george, vice, adams, presidents, born, house, paul, kennedy, washington, bush, said, wrote, jefferson, elected, chief, quincy, court\n",
      "\n",
      "Topic  18\n",
      "century, america, history, british, art, bc, early, years, work, william, wrote, people, women, known, artists, french, late, empire, painting, famous\n",
      "\n",
      "Topic  19\n",
      "man, said, young, george, old, people, art, good, famous, men, wrote, died, woman, literary, west, thomas, god, became, hes, whos\n",
      "\n",
      "Topic  20\n",
      "last, letter, alphabetically, add, number, get, years, battle, famous, british, presidential, letters, alphabet, supper, emperor, category, take, mohicans, perfect, home\n",
      "\n",
      "Topic  21\n",
      "book, novel, books, old, bible, wrote, authors, testament, good, author, little, literature, titles, biblical, lit, published, says, james, story, childrens\n",
      "\n",
      "Topic  22\n",
      "title, film, movie, character, play, movies, novel, played, fill, oscar, literary, opera, characters, completes, role, best, pairs, shakespeare, films, based\n",
      "\n",
      "Topic  23\n",
      "type, called, used, made, food, get, french, white, science, term, make, red, game, known, body, company, house, part, often, blue\n",
      "\n",
      "Topic  24\n",
      "song, hit, music, love, rock, top, musical, songs, pop, band, little, group, know, go, lyrics, roll, got, hits, says, wrote\n"
     ]
    }
   ],
   "source": [
    "display_topics(nmf2, tfidf2.get_feature_names(), 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Custom Quiz Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(doc1, doc2):\n",
    "    '''Finds cosine similarity between two rows of doc-term matrix'''\n",
    "    cosine = dot(doc1, doc2) / (norm(doc1) * norm(doc2))                         \n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07348890188311234"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(corpus_tf2_nmf[0], corpus_tf2_nmf[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputs 10 most similar questions to the one I got wrong\n",
    "def get_closest_qs(doc, doc_term, questions, no_qs):\n",
    "    '''Finds cosine similarity between one question and all others, then returns the n-most similar questions'''\n",
    "    results = []\n",
    "    for idx, _ in enumerate(doc_term):\n",
    "        results.append(cosine_similarity(doc, doc_term[idx]))    \n",
    "    return list(zip(questions.iloc[np.argsort(results)[-no_qs:]],results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('166385 AMERICAN WOMEN NOVELISTS: \\'The author of \"A Stranger is Watching\", she\\'s been called \"America\\'s Queen of Suspense\"\\'',\n",
       "  0.10024014904518536),\n",
       " ('157560 WELL, \"B\"!: \\'In Exodus 2:3 baby Moses is cruising down the Nile River in a basket made from these\\'',\n",
       "  0.2774838326995913),\n",
       " ('42881 AMERICAN POETS & POETRY: \\'This line follows \"Poems are made by fools like me\"\\'',\n",
       "  0.0022459164545551758),\n",
       " ('55468 AMERICAN LIT: \\'A Hemingway story is called \"The Short Happy Life of\" him\\'',\n",
       "  0.30287517783359585),\n",
       " (\"29145 POTENT POTABLES: 'With brands like Old Overholt, whiskey made from this grain, not corn, was once a favorite of the American sot'\",\n",
       "  0.18189736055551123),\n",
       " ('178310 ROBERT LOUIS STEVENSON: \\'When Stevenson wrote this tale in 1881, it was called \"The Sea-Cook\"\\'',\n",
       "  0.0),\n",
       " ('192982 AMERICAN POETRY: \\'In what he called a favorite poem, Wallace Stevens wrote, \"The only emperor is the emperor of this dessert treat\"\\'',\n",
       "  0.7569429459719069),\n",
       " ('56077 AUTHORS\\' QUOTATIONS: \\'\"I had no idea of originating an American flapper... I simply took girls whom I knew very well\" & \"used them for my heroines\"\\'',\n",
       "  0.12939468192769693),\n",
       " ('192970 AMERICAN POETRY: \\'Even in a poem called \"Desert Places\", he wrote about \"The ground almost covered smooth in snow\"\\'',\n",
       "  0.038132294919496004),\n",
       " ('71121 ALWAYS BE CLOSING: \\'Educator Allan Bloom wrote a 1987 bestseller called \"The Closing Of The American\" this\\'',\n",
       "  0.10441576032828546)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest_qs(corpus_tf2_nmf[34538], corpus_tf2_nmf, jdf_qanda['question'], no_qs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #use this to get answers from quiz (no functional advantage to simply accessing the dataframe answers as shown below)\n",
    "# def get_closest_as(indices, answers):\n",
    "#     '''Returns answers corresponding to the questions whose indices are provided in the form of a list'''\n",
    "#     for i in indices:\n",
    "#         print(str(answers.loc[answers['idx'] == i, 'answer'].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195340 (Eero) Saarinen\n"
     ]
    }
   ],
   "source": [
    "# get_closest_as([195340], jdf_qanda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get Random Question**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_q(questions):\n",
    "    x = np.random.randint(0,100000)\n",
    "    return questions.iloc[x,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"34538 FIRST ELECTED OFFICE: 'This New York junior senator's first elected office was... New York junior senator'\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_q(jdf_qanda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'34538 Hillary Clinton'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jdf_qanda['answer'][34538]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Count Vectorizer with LDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(ngram_range=(1,2),  \n",
    "                                   stop_words=stop_words, token_pattern=\"\\\\b[a-z][a-z]+\\\\b\")\n",
    "\n",
    "count_vectorizer.fit(corpus)\n",
    "corpus_cv1 = count_vectorizer.transform(corpus).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_cv1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(corpus_cv1.toarray(), count_vectorizer.get_feature_names()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsparse_cv1 = matutils.Sparse2Corpus(corpus_cv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = dict((v, k) for k, v in count_vectorizer.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda30 = models.LdaModel(corpus=unsparse_cv1, num_topics=30, id2word=id2word, passes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lda30.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF-IDF with LDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf1 = TfidfVectorizer(ngram_range=(1,2),\n",
    "                         stop_words=stop_words, token_pattern=\"\\\\b[a-z][a-z]+\\\\b\")\n",
    "\n",
    "tfidf1.fit(corpus)\n",
    "corpus_tf1 = tfidf1.transform(corpus).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(corpus_tf1.toarray(), tfidf1.get_feature_names()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsparse_tf1 = matutils.Sparse2Corpus(corpus_tf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = dict((v, k) for k, v in tfidf1.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_tf_30 = models.LdaModel(corpus=unsparse_tf1, num_topics=30, id2word=id2word, passes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_tf_30.print_topics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.444px",
    "left": "1141.11px",
    "right": "20px",
    "top": "121px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
